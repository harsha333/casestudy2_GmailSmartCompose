{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "88bdbsvX94CN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, Bidirectional, GRU, Concatenate\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "import re\n",
    "import math\n",
    "from keras import backend\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os, datetime\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kqUJxgtP-AAm"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ierq2hMO5GO-",
    "outputId": "921c935e-e49b-47d1-9592-8757515d594a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M7Zq8Rm46N0"
   },
   "source": [
    "Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CQUejk1N44f3"
   },
   "outputs": [],
   "source": [
    "final_model = load_model(\"/content/drive/MyDrive/CaseStudy2/final_model.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mblBZq2249mA"
   },
   "outputs": [],
   "source": [
    "test_model = load_model(\"/content/drive/MyDrive/CaseStudy2/test_model.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXntArUv52qX",
    "outputId": "28a75453-9d6b-4814-c4bf-267211b6ebb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 21, 10)       100000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 21, 384), (N 235008      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][2]              \n",
      "==================================================================================================\n",
      "Total params: 335,008\n",
      "Trainable params: 335,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdNdbCpk53Ti",
    "outputId": "a13fb8fa-75c8-4975-edbb-a5290c5f56d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 10)     100000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, None, 384),  456192      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    49280       gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10000)  1290000     dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,895,472\n",
      "Trainable params: 1,895,472\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-7EKNS7Y5TUu"
   },
   "outputs": [],
   "source": [
    "max_len_size_vocab = 10000\n",
    "\n",
    "with open('/content/drive/MyDrive/CaseStudy2/word_dict-final.json') as f:\n",
    "    dict_words = json.load(f)\n",
    "    toknizer = Tokenizer(filters='', num_words=max_len_size_vocab)\n",
    "    toknizer.word_index = dict_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XqQcItf8_rOj"
   },
   "outputs": [],
   "source": [
    "max_len_in = 21\n",
    "max_len_out = 20\n",
    "def test_tokenize_data(data):\n",
    "    data = data.lower()\n",
    "    data = '<start> ' + data + ' <end>'\n",
    "    data_tf = toknizer.texts_to_sequences([data])\n",
    "    data_tf = pad_sequences(data_tf, maxlen=max_len_in, padding=\"post\")\n",
    "    return data_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6Vdlh4w_ALoh"
   },
   "outputs": [],
   "source": [
    "integer2words = map(reversed, toknizer.word_index.items())\n",
    "integer2words = dict(integer2words)\n",
    "def get_testoutput(query_point):\n",
    "    st = final_model.predict(query_point)\n",
    "    sequence_output = np.zeros((1, 1))\n",
    "    sequence_output[0, 0] = toknizer.word_index['<start>']\n",
    "    present = \"<start>\"\n",
    "    sen_final = ''\n",
    "    k = 0\n",
    "    while present != \"<end>\" and k < (max_len_out - 1):\n",
    "        tkns_final, st_h = test_model.predict([sequence_output, st])\n",
    "\n",
    "        tkn_present = np.argmax(tkns_final[0, 0])\n",
    "\n",
    "        if (tkn_present == 0):\n",
    "          break;\n",
    "\n",
    "        present = integer2words[tkn_present]\n",
    "\n",
    "        sen_final += ' ' + present\n",
    "        sequence_output[0, 0] = tkn_present\n",
    "        st = st_h\n",
    "        k += 1\n",
    "\n",
    "    return sen_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "inywcd_wA2q1"
   },
   "outputs": [],
   "source": [
    "def getWords(w):\n",
    "    res=''\n",
    "    if w!=0:\n",
    "      res = integer2words[w]\n",
    "    else:\n",
    "      res = ''\n",
    "    return res\n",
    "\n",
    "def tkns2seq(inputs):\n",
    "  \n",
    "  sentnces = list(map(getWords, inputs))\n",
    "  result = ' '.join(sentnces)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "sPllz_wQAe7L"
   },
   "outputs": [],
   "source": [
    "query_points = ['shall we connect in', \n",
    "                'have a', \n",
    "                'let me know',\n",
    "                'please find my',\n",
    "                'please find my resume',\n",
    "                'I am',\n",
    "                'can we',\n",
    "                'As discussed can we connect this',\n",
    "                'I will finalize and submit the project in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79qocBAmA-nu",
    "outputId": "b59fffda-8272-4396-e68e-440ec2563b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY_POINT: shall we connect in  NEXT SEQUENCE:  the office on friday. thanks <end>\n",
      "QUERY_POINT: have a  NEXT SEQUENCE:  good <end>\n",
      "QUERY_POINT: let me know  NEXT SEQUENCE:  if you have any questions. <end>\n",
      "QUERY_POINT: please find my  NEXT SEQUENCE:  attached links report. jerry graves <end>\n",
      "QUERY_POINT: please find my resume  NEXT SEQUENCE:  for the attached ngi chicago employees. <end>\n",
      "QUERY_POINT: I am  NEXT SEQUENCE:  going to be out of the office until <end>\n",
      "QUERY_POINT: can we  NEXT SEQUENCE:  send me the latest gtc's for the game. thanks russell <end>\n",
      "QUERY_POINT: As discussed can we connect this  NEXT SEQUENCE:  week. <end>\n",
      "QUERY_POINT: I will finalize and submit the project in  NEXT SEQUENCE:  the interstate pipelines? <end>\n"
     ]
    }
   ],
   "source": [
    "for i in query_points:\n",
    "    result_qp = get_testoutput(test_tokenize_data(i))\n",
    "    print(f\"QUERY_POINT: {i}  NEXT SEQUENCE: {result_qp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jd3ofhB772yp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "caseStudy2final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
